{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 implementation using CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import CSVLogger, EarlyStopping\n",
    "from keras.initializers import glorot_uniform\n",
    "import cv2\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train = np.array([cv2.resize(img, (64,64)) for img in X_train[:10000,:,:,:]])\n",
    "X_test = np.array([cv2.resize(img, (64,64)) for img in X_test[:1000,:,:,:]])\n",
    "\n",
    "n_classes = 10\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train[:10000,:], n_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test[:1000,:], n_classes)\n",
    "\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train -= mean_image\n",
    "X_test -= mean_image\n",
    "X_train /= 128.\n",
    "X_test /= 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64, 64, 3)\n",
      "(10000, 10)\n",
      "(1000, 64, 64, 3)\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print Y_train.shape\n",
    "print X_test.shape\n",
    "print Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_x, kernels, filter_sizes, strides):\n",
    "    input_shortcut = input_x\n",
    "    \n",
    "    k1, k2, k3 = kernels\n",
    "    f1, f2, f3 = filter_sizes\n",
    "    s1, s2, s3 = strides\n",
    "    \n",
    "    X = layers.Conv2D(k1, kernel_size=(f1,f1), strides=(s1,s1), padding=\"valid\", kernel_initializer = glorot_uniform(seed=0))(input_x)\n",
    "    X = layers.BatchNormalization(axis=3)(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    \n",
    "    X = layers.Conv2D(k2, kernel_size=(f2,f2), strides=(s2,s2), padding=\"same\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = layers.BatchNormalization(axis=3)(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "\n",
    "    X = layers.Conv2D(k3, kernel_size=(f3,f3), strides=(s3,s3), padding=\"valid\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = layers.BatchNormalization(axis=3)(X)\n",
    "    \n",
    "    input_shortcut = layers.Conv2D(k3, kernel_size=(f3, f3), strides=(s1,s1), padding=\"valid\", kernel_initializer=glorot_uniform(seed=0))(input_shortcut)\n",
    "    input_shortcut = layers.BatchNormalization()(input_shortcut)\n",
    "    \n",
    "    X = layers.Add()([input_shortcut,X])\n",
    "    X = layers.Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_x, kernels, filter_sizes, strides):\n",
    "    input_shortcut = input_x\n",
    "    \n",
    "    k1, k2, k3 = kernels\n",
    "    f1, f2, f3 = filter_sizes\n",
    "    s1, s2, s3 = strides\n",
    "    \n",
    "    X = layers.Conv2D(k1, kernel_size=(f1,f1), strides=(s1,s1), padding=\"valid\", kernel_initializer = glorot_uniform(seed=0))(input_x)\n",
    "    X = layers.BatchNormalization(axis=3)(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    \n",
    "    X = layers.Conv2D(k2, kernel_size=(f2,f2), strides=(s2,s2), padding=\"same\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = layers.BatchNormalization(axis=3)(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "\n",
    "    X = layers.Conv2D(k3, kernel_size=(f3,f3), strides=(s3,s3), padding=\"valid\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = layers.BatchNormalization(axis=3)(X)\n",
    "    \n",
    "    X = layers.Add()([input_shortcut,X])\n",
    "    X = layers.Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape, n_classes):\n",
    "    \n",
    "    input_x = layers.Input(input_shape)\n",
    "    \n",
    "    X = layers.ZeroPadding2D((3,3))(input_x)\n",
    "    \n",
    "    X = layers.Conv2D(64, kernel_size=(7,7), strides=(2,2), padding=\"same\", kernel_initializer = glorot_uniform(seed=0))(input_x)\n",
    "    X = layers.BatchNormalization(axis=3)(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    X = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2))(X)\n",
    "    \n",
    "    X = conv_block(X, [64, 64, 256], [1, 3, 1], [1, 1, 1])\n",
    "    X = identity_block(X, [64, 64, 256], [1, 3, 1], [1, 1, 1])\n",
    "    X = identity_block(X, [64, 64, 256], [1, 3, 1], [1, 1, 1])\n",
    "    \n",
    "    X = conv_block(X, [128, 128, 512], [1, 3, 1], [2, 1, 1])\n",
    "    X = identity_block(X, [128, 128, 512], [1, 3, 1], [1, 1, 1])\n",
    "    X = identity_block(X, [128, 128, 512], [1, 3, 1], [1, 1, 1])\n",
    "    X = identity_block(X, [128, 128, 512], [1, 3, 1], [1, 1, 1])\n",
    "    \n",
    "    X = conv_block(X, [256, 256, 1024], [1, 3, 1], [2, 1, 1])\n",
    "    X = identity_block(X, [256, 256, 1024], [1, 3, 1], [1, 1, 1])\n",
    "    X = identity_block(X, [256, 256, 1024], [1, 3, 1], [1, 1, 1])\n",
    "    X = identity_block(X, [256, 256, 1024], [1, 3, 1], [1, 1, 1])\n",
    "    X = identity_block(X, [256, 256, 1024], [1, 3, 1], [1, 1, 1])\n",
    "    X = identity_block(X, [256, 256, 1024], [1, 3, 1], [1, 1, 1])\n",
    "    \n",
    "    X = conv_block(X, [512, 52, 2048], [1, 3, 1], [2, 1, 1])\n",
    "    X = identity_block(X, [512, 52, 2048], [1, 3, 1], [1, 1, 1])\n",
    "    X = identity_block(X, [512, 52, 2048], [1, 3, 1], [1, 1, 1])\n",
    "    \n",
    "    #pool_size = (7,7) in orignal implementation\n",
    "    X = layers.AveragePooling2D(pool_size=(2,2), strides=(1,1))(X)\n",
    "    \n",
    "    X = layers.Flatten()(X)\n",
    "    X = layers.Dense(n_classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    resnet50_model = keras.models.Model(inputs=input_x, outputs=X, name='resnet50')\n",
    "    \n",
    "    return resnet50_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_shape of (224,224,3) in orignal implementation\n",
    "resnet50_model = ResNet50(input_shape = (64, 64, 3), n_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10000/10000 [==============================] - 500s 50ms/step - loss: 2.7489 - acc: 0.1876\n",
      "Epoch 2/3\n",
      "10000/10000 [==============================] - 493s 49ms/step - loss: 2.4075 - acc: 0.2772\n",
      "Epoch 3/3\n",
      "10000/10000 [==============================] - 493s 49ms/step - loss: 2.4595 - acc: 0.2809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73217a9e90>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50_model.fit(X_train, Y_train, epochs = 3, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
